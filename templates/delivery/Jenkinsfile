// Used to skip the Snyk scan when a previous step fails
def skip_snyk_scan = false

pipeline {
  parameters {
    string(name: 'git_repository', description: 'The URL of the Git repository to clone when building the container image.')
    string(name: 'git_commit', description: 'The commit hash or branch name to checkout when building the container image.')
    string(name: 'git_credentials', description: 'The ID of the Jenkins credentials to use when cloning the Git repository.')
    booleanParam(name: 'image_push_enabled', defaultValue: "${default_image_push_enabled ?: false}", description: 'Enable the image push step.')
    string(name: 'image', defaultValue: "${default_image ?: 'my-app'}", description: 'The fully qualified container image name.')
    string(name: 'tag', defaultValue: "${default_tag ?: 'latest'}", description: 'Container image tag.')

    booleanParam(name: 'update_latest', defaultValue: "${default_update_latest ?: false}", description: 'When true, update the latest tag to point to the newly built image.')
    string(name: 'build_args', defaultValue: "${default_build_args ?: '{}'}", description: 'A JSON object of build arguments to pass to the container build process.')
    string(name: 'build_dir', defaultValue: "${default_build_dir ?: '.'}", description: 'The directory to use as the build context for the container build.')
    string(name: 'dockerfile', defaultValue: "${default_dockerfile ?: 'Dockerfile'}", description: 'The path to the Dockerfile to use for the container build.')
    string(name: 'build_target', defaultValue: "${default_build_target ?: ''}", description: 'The build target to use when building the container image (for use with multi-stage Dockerfiles).')
    string(name: 'copy_artifacts_job_name', defaultValue: '', description: 'Optional, name of the Jenkins job from which to copy build artifacts that may be required by the Dockerfile.')
    string(name: 'copy_artifacts_build_number', defaultValue: '', description: 'Optional, specific build number of artifacts to copy.')
    string(name: 'copy_artifacts_filter', defaultValue: '', description: 'Optional, filemask to identify build artifacts to copy.')
    choice(name: 'log_level', choices: ['info', 'panic', 'fatal', 'error', 'warn', 'debug', 'trace'], description: 'The log level to use for the container build process.')
    string(name: 'build_memory_limit', defaultValue: "${default_build_memory_limit ?: '1Gi'}", description: "Memory limit for the image build process.")
    string(name: 'build_cpu_limit', defaultValue: "${default_build_cpu_limit ?: '1'}", description: "CPU limit for the image build process.")
    booleanParam(name: 'clamscan_enabled', defaultValue: true, description: 'optionally enable/disable the clamscan antivirus scan.')
    // TODO: caching for buildx ??
    // booleanParam(name: 'enable_cache', defaultValue: "${default_enable_cache ?: false}", description: 'Enable Kaniko image build cache.')

    string(name: 'snyk_project_name', defaultValue: "${default_snyk_project_name ?: 'my-app'}", description: 'The name of the Snyk project to associate the container image scan with.')
    string(name: 'vulnerability_severity_threshold', defaultValue: "${default_vulnerability_severity_threshold ?: 'high'}", description: 'The minimum severity level of vulnerabilities which will cause the build to fail if detected (options: low, medium, high, critical).')

    booleanParam(name: 'continue_on_image_scan_failure', defaultValue: "${default_continue_on_image_scan_failure ?: false}", description: 'When set to true, the pipeline will continue to the image publish step even if either of the malware scan or vulnerability scan fails for any reason.')
  }

  agent {
    kubernetes {
      yaml """
      apiVersion: v1
      kind: Pod
      metadata:
        annotations:
          com.cloudbees.sidecar-injector/inject: no
      spec:
        restartPolicy: Never
        containers:
        - name: fetch
          image: artifactory.cloud.cms.gov/docker/alpine:3
          command: ['tail', '-f', '/dev/null']
        - name: buildx
          image: docker:latest
          command: ['tail', '-f', '/dev/null']
        - name: clamav
          image: artifactory.cloud.cms.gov/docker/clamav/clamav:latest
          command: ['tail', '-f', '/dev/null']
          resources:
            limits:
              memory: "5Gi"
            requests:
              memory: "3Gi"
        - name: snyk
          image: artifactory.cloud.cms.gov/docker/snyk/snyk:alpine
          command: ['tail', '-f', '/dev/null']
        - name: skopeo
          # pull through from quay.io
          image: artifactory.cloud.cms.gov/docker/skopeo/stable:v1
          command: ['tail', '-f', '/dev/null']
      """
    }
  }

  options {
    // Allow other pipelines to copy the artifacts produced by this pipeline
    copyArtifactPermission('*')
    // Automatically discard old builds
    buildDiscarder(logRotator(daysToKeepStr: "${build_retention_days}", numToKeepStr: "${build_retention_count}"))
  }

  stages {
    stage('Fetch Source Code & Artifacts') {
      steps {
        container('fetch') {
          script {
            checkout scmGit(
              branches: [[ name: "${params.git_commit}" ]],
              userRemoteConfigs: [[
                url: "${params.git_repository}",
                credentialsId: "${params.git_credentials}",
                refspec: "+${params.git_commit}:refs/remotes/origin/HEAD"
              ]],
              extensions: [
                cloneOption(shallow: true, honorRefspec: true, noTags: true),
                submodule(recursiveSubmodules: true, shallow: true)
              ]
            )

            if (params.copy_artifacts_job_name && params.copy_artifacts_build_number && params.copy_artifacts_filter) {
              copyArtifacts projectName: params.copy_artifacts_job_name, filter: params.copy_artifacts_filter, selector: specific(params.copy_artifacts_build_number)
            }
          }
        }
      }
    }

    stage('Build Image - buildx') {
      steps {
        container('buildx') {
          script {
            def builderName = "buildkit-builder-${UUID.randomUUID().toString().substring(0, 8)}"
            sh "docker buildx create --name ${builderName} --driver kubernetes --driver-opt=limits.memory=${params.build_memory_limit},limits.cpu=${params.build_cpu_limit} --use"
            try {
              def arguments = [
                "--file=${params.dockerfile}",
                "--tag=${params.image}:${params.tag}",
                "--output type=oci,dest=./image.oci.tar",
                "--output type=local,dest=./image-raw"
              ]

              if (params.build_target) {
                echo "build_target (${params.build_target.getClass()}): ${params.build_target}"
                echo "default_build_target: ${default_build_target}"
                arguments.add("--target=${params.build_target}")
              }

              if (params.build_args) {
                def argMap = new groovy.json.JsonSlurper().parseText(params.build_args)
                argMap.each { key, value ->
                  arguments.add("--build-arg=${key}='${value}'")
                }
              }

              build_command = "docker buildx build ${arguments.join(' ')} ${params.build_dir}"

              // Authentication by copying a docker config JSON to config directory
              withCredentials([file(credentialsId: "${image_registry_auth_json}", variable: 'AUTH_JSON_FILE')]) {
                echo "export image registry auth json to ~/.docker/config.json"
                sh 'mkdir -p ~/.docker'
                sh 'mv "$AUTH_JSON_FILE" ~/.docker/config.json'

                if ("${enable_ansi_colors}" == "true") {
                  ansiColor('xterm') {
                    sh build_command
                  }
                } else {
                  sh build_command
                }
              }
            } finally {
              sh "docker buildx rm --force ${builderName}"
            }
          }
        }
      }
    }

    stage('Image Scan') {
      parallel {
        stage('Vulnerability Scan') {
          steps {
            container('snyk') {
              script {
                // When Snyk reports findings it uses the filename as the "target" in the dashboard,
                // so using the image name as the filename keeps things better organized.
                // Unfortunately since filenames cannot contain / we have to replace them with _.
                def image_file_name = "'${params.image}:${params.tag}'".replace('/', '_')
                sh "ln image.oci.tar ${image_file_name}"
                def args = [
                  // Application vulnerabilities can be detected using `snyk test` as part of the SAST step
                  '--exclude-app-vulns',
                  "--severity-threshold=${params.vulnerability_severity_threshold}",
                  "--project-name=${params.snyk_project_name}",
                  "oci-archive:${image_file_name}"
                ]
                def sbom_ext = "${sbom_format}".tokenize('+')[1]
                try {
                  withCredentials([string(credentialsId: "${snyk_token}", variable: 'SNYK_TOKEN')]) {
                    sh """
                      # Report vulnerabilities to the Snyk dashboard
                      snyk container monitor ${args.join(' ')}
                      snyk container sbom --format=${sbom_format} oci-archive:image.oci.tar > './snyk-sbom.${sbom_ext}'
                      # Report detected vulnerabilities to stdout and raise an error if
                      # vulnerabilities are found exceeding the specified threshold
                      snyk container test --json-file-output=snyk-vulnerabilities.json ${args.join(' ')}
                    """
                  }

                // If there is an error during the snyk scan
                } catch(err) {

                  if (params.continue_on_image_scan_failure) {
                    catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                      error "Failed to scan the image with Snyk. Continuing pipeline execution."
                    }
                  } else {
                    echo "Snyk scan failed with error: ${err}"
                    error "Failed to scan the image with Snyk."
                  }

                // No matter what, make sure the artifacts are archived
                } finally {
                  archiveArtifacts artifacts: 'snyk-sbom.*, snyk-vulnerabilities.json', allowEmptyArchive: true
                }

              } // end script block
            } // end  container snyk
          } // end steps
        } // end vulnerability scan stage


        stage('Malware Scan') {
          steps {
            container('clamav') {
              script {
                try {
                  echo "Updating ClamAV database"
                  def freshclamExitCode = sh(script: "freshclam", returnStatus: true)
                  if (freshclamExitCode != 0) {
                    echo "Freshclam exited with code ${freshclamExitCode}"
                    error 'Failed to update ClamAV database.'
                  }
                  echo "ClamAV database updated successfully, running clamscan"
                  sh """
                    # Note: while clamscan can scan a tar files contents recursively, the
                    # max-filesize and max-scansize limit still apply to the tar file itself. So if
                    # the image tar files is scanned unextracted it will be a no-op if the file is
                    # larger than the max-filesize limit.
                    clamscan --infected --recursive --scan-archive=yes --max-filesize=500M --max-scansize=500M \
                             --log virus-report.clamav.txt --stdout ./image-raw

                    chmod a+r virus-report.clamav.txt
                  """

                } catch(err) {
                  if (params.continue_on_image_scan_failure) {
                    catchError(buildResult: 'SUCCESS', stageResult: 'UNSTABLE') {
                      error "Failed to scan the image with ClamAV. Continuing pipeline execution."
                    }
                  } else {
                    error "Failed to scan the image with ClamAV."
                  }
                } finally {
                  archiveArtifacts artifacts: 'virus-report.clamav.txt', allowEmptyArchive: true
                }
              }
            }
          }
        } // end stage malware scan
      } // end parallel
    } // end image scan stage

    stage('Image Publish') {
      when {
        expression { params.image_push_enabled }
      }
      steps {
        container('skopeo') {
          script {
            // Authentication by copying a docker config JSON to config directory
            withCredentials([file(credentialsId: "${image_registry_auth_json}", variable: 'AUTH_JSON_FILE')]) {
              sh """
                skopeo copy --dest-authfile "\$AUTH_JSON_FILE" oci-archive:image-oci.tar "docker:${params.image}:${params.tag}"
              """

              if (params.update_latest) {
                sh """
                  skopeo copy --dest-authfile "\$AUTH_JSON_FILE" oci-archive:image-oci.tar "docker:${params.image}:latest"
                """
              }
            }
          }
        }
      }
    }
  } // end stages
} // end pipelines
